{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "#get_ipython().magic(u'matplotlib inline')\n",
    "import cPickle\n",
    "from multiprocessing import Pool\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dataframe2corpus(df,name_file):\n",
    "    '''\n",
    "    df : dataframe containing the data\n",
    "    name_file : name of file saved containing the dictionnary for the lda model\n",
    "    '''\n",
    "    non_num_columns=['AffinityCodeId','SelectedPackage','NameOfPolicyProduct','SCID']\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for column in non_num_columns:\n",
    "        df[column]=le.fit_transform(df[column].as_matrix())\n",
    "    dropped_columns=['CustomerMD5Key','ReceivedDateTime','Unnamed: 0','TodayDate']\n",
    "    all_columns=df.columns.tolist()\n",
    "    for column_name in dropped_columns:\n",
    "        all_columns.remove(column_name)\n",
    "\n",
    "    reduced_df=df[all_columns]\n",
    "    \n",
    "    # List of column names with categorical variables\n",
    "    categ_vars=[]\n",
    "    for column in reduced_df.columns:\n",
    "        if len(np.unique(reduced_df[column]))<50:    # we don't keep columns with too many different values\n",
    "            categ_vars+=[column]\n",
    "\n",
    "# Encode the data as a bag of words to feed gensim LDA\n",
    "    equiv_texts=[]\n",
    "    all_cat=reduced_df[categ_vars].as_matrix().tolist()\n",
    "    for row in all_cat:\n",
    "        text_row=[str(categ_vars[i])+':'+str(word) for (i,word) in enumerate(row)]\n",
    "        equiv_texts+=[text_row]\n",
    "    \n",
    "    \n",
    "    #dictionary = corpora.Dictionary(equiv_texts)\n",
    "    #dictionary.save('topics_'+str(name_file)+'.dict') # dictionnary id2word\n",
    "    dictionary=corpora.Dictionary.load('topics_alex.dict')\n",
    "    \n",
    "    \n",
    "    \n",
    "    corpus = [dictionary.doc2bow(text) for text in equiv_texts]\n",
    "    corpora.MmCorpus.serialize('topics_'+str(name_file)+'.mm', corpus) # serialized dictionnary (for fast lda)\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n_topics=5\n",
    "\n",
    "name_file='final'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test=pd.read_csv('X_test.csv')\n",
    "#X_train=pd.read_csv('X_train.csv')\n",
    "\n",
    "df=X_test\n",
    "del X_test\n",
    "\n",
    "dataframe2corpus(df,name_file)\n",
    "lenX=np.shape(df.as_matrix())[0]\n",
    "del df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# step 2 : \n",
    "\n",
    "lda=cPickle.load(open('lda_alex_'+str(n_topics)+'_topics.p','rb')) # load lda model trained on the big corpus\n",
    "\n",
    "mm_test = corpora.MmCorpus('topics_'+str(name_file)+'.mm')\n",
    "id2word = corpora.Dictionary.load('topics_alex.dict')\n",
    "   \n",
    "ldamm=lda[mm_test]\n",
    "del mm_test,lda # saving memory\n",
    "L_indices=list(range(lenX)) ##########\n",
    "\n",
    "\n",
    "def transform_vocab(idx_doc_bow):\n",
    "    global n_topics,ldamm\n",
    "    bow_converted=ldamm[idx_doc_bow]\n",
    "    local_array=[0]*(n_topics+1)\n",
    "    for feat_tuple in bow_converted:\n",
    "        local_array[feat_tuple[0]+1]=feat_tuple[1]\n",
    "    return local_array\n",
    "        \n",
    "# Compute the feature vector :\n",
    "p=Pool(10)\n",
    "a=p.map(transform_vocab,L_indices)\n",
    "\n",
    "cPickle.dump(a,open('sauvegarde_qui_sauve_la_vie.p','wb'))\n",
    "topic_features_df=pd.DataFrame(a)\n",
    "del a\n",
    "topic_features_df=topic_features_df[topic_features_df.columns[1:]]\n",
    "topic_features_df.columns=['lda_feature_'+str(i) for i in range(len(topic_features_df.columns))]\n",
    "topic_features_df.to_csv('lda_features_'+str(n_topics)+'_'+str(name_file)+'_topics_df.csv',index=None)\n",
    "#compute_lda_feature(n_topics,name_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_topics=5\n",
    "lda=cPickle.load(open('lda_alex_'+str(n_topics)+'_topics.p','rb')) # load lda model trained on the big corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'0.053*SelectedPackage:1.0 + 0.052*FirstDriverDrivingLicenceType:1.0 + 0.051*IsPolicyholderAHomeowner:1.0 + 0.050*FirstDriverMaritalStatus:2.0 + 0.049*AllDriversNbConvictions:0.0 + 0.045*RatedDriverNumber:1.0 + 0.039*CarParkingTypeId:2.0 + 0.038*PolicyHolderNoClaimDiscountYears:9.0 + 0.038*CoverIsNoClaimDiscountSelected:1.0 + 0.036*CarDrivingEntitlement:2.0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.print_topic(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
